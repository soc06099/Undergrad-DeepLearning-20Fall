{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from dd_nnutil_hallym_batchcrop import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow와 tf.keras를 포함한 라이브러리를 임포트합니다\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nnutil_20 import random_crop\n",
    "#from nnutil_20 import center_crop\n",
    "from nnutil_20 import crop_generator\n",
    "from nnutil_20 import GetTimeString\n",
    "from nnutil_20 import MakeDir\n",
    "from nnutil_20 import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datadir = './dataset/handpose_20F_small_mini'\n",
    "datadir = './dataset/handpose_20F_small_training'\n",
    "datadir_val = './dataset/handpose_20F_small_100_val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python 에서 리눅스 명령어를 사용하려면 아래처럼 ! 로 시작\n",
    "\n",
    "    ls --> !ls\n",
    "\n",
    "리눅스 명령어에 파이썬 변수를 사용하려면 $ 를 붙이고 사용\n",
    "\n",
    "    datadir --> $datadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $datadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $datadir_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MakeDir('out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 불러오기 Generator 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 1.1 # 그림 크기를 줄일 비율 (factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size=(int(300//f), int(400//f))\n",
    "print(target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        datadir,\n",
    "        target_size=target_size, #150,200\n",
    "        batch_size=32*4, \n",
    "        shuffle=True,\n",
    "        class_mode='categorical' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = val_datagen.flow_from_directory(\n",
    "        datadir_val,\n",
    "        target_size=target_size,#150,200\n",
    "        batch_size=16,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(train_generator.class_indices)\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 224 # 줄여진 그림을 (w, w) 크기로 crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crops = crop_generator(train_generator, w) #224\n",
    "val_crops = crop_generator(val_generator, w) #224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_shape=(300//f, 400//f, 3)\n",
    "#input_shape=(224, 224, 3)\n",
    "input_shape=(w, w, 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstring = GetTimeString()#DDUtil\n",
    "print(tstring)\n",
    "\n",
    "#x,y = train_generator.next()\n",
    "x,y = next(train_crops)\n",
    "print(x.shape) # (128, 100, 100, 3) = (배치갯수, h, w, 채널)\n",
    "print(y.shape) # (128, 6) = (배치갯수, 클래스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    image = x[i]\n",
    "    f1=plt.figure()\n",
    "    imshow(image, '{}'.format(y[i]))\n",
    "    fnfig = 'out/{}_{}.png'.format(tstring, i)\n",
    "    io.imsave(fnfig, image)\n",
    "    #f1 = plt.gcf()\n",
    "    fnfig = 'out/{}_{}_fig.png'.format(tstring, i)\n",
    "    f1.savefig(fnfig)\n",
    "    print(fnfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32,(3,3), activation='relu', input_shape=input_shape),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    #keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    keras.layers.MaxPool2D(2,2),\n",
    "    keras.layers.Conv2D(128,(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(2,2),\n",
    "    \n",
    "    keras.layers.Conv2D(128,(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(2,2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(n_classes, activation='softmax')])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps_per_epoch should be (number of training images total / batch_size) \n",
    "# validation_steps should be (number of validation images total / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit_generator(train_generator, steps_per_epoch = 50, epochs=50)\n",
    "\n",
    "history = model.fit_generator(train_crops, \n",
    "                              steps_per_epoch = 50, \n",
    "                              epochs=50, \n",
    "                              validation_data=val_crops, #val_generator\n",
    "                              validation_steps=50 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 모델 저장하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('handpose_{}.h5'.format(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 과정 살펴보기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(10,5))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss', linewidth=1)\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss', linewidth=1)\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['accuracy'], 'b', label='train acc', linewidth=1)\n",
    "acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc', linewidth=1)\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper center')\n",
    "#plt.title(cellName[celltype])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = datadir_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_generator = val_datagen.flow_from_directory(\n",
    "test_dir,target_size=target_size,#150,200\n",
    "batch_size=BATCH_SIZE,\n",
    "shuffle=False,\n",
    "seed=42)\n",
    "eval_crops = crop_generator(eval_generator, w) #224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.evaluate_generator(eval_crops,\n",
    " steps = np.ceil(len(eval_generator) / BATCH_SIZE),\n",
    " use_multiprocessing = False,\n",
    " verbose = 1,\n",
    " workers=1\n",
    " )\n",
    "print('Test loss:' , res[0])\n",
    "print('Test accuracy:',res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test 정확도 : {:.2f}%'.format(res[1] * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하나만 꺼내서 테스트 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_x,eval_y = next(eval_crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_x.shape # (1, 100, 100, 3) = (배치갯수, h, w, 채널)\n",
    "             # 이 경우 batch 갯수는 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_y.shape #(1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_array = model.predict(eval_x)\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = np.argmax(predictions_array[0]) #batch 를 고려해서 [0] 번째 를 명시함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prob = np.max(predictions_array[0]) #batch 를 고려해서 [0] 번째 를 명시함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(n_classes), predictions_array[0], color=\"#777777\")\n",
    "plt.ylabel('prob')\n",
    "plt.xlabel('pose index')\n",
    "plt.title('Prediction: #{} --> {:.2f}%'.format(max_idx, max_prob*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstring = GetTimeString()#DDUtil\n",
    "image = eval_x[0]\n",
    "f1=plt.figure()\n",
    "imshow(image, 'Prediction: #{} --> {:.2f}%'.format(max_idx, max_prob*100.0))\n",
    "fnfig = 'out/{}_eval.png'.format(tstring)\n",
    "io.imsave(fnfig, image)\n",
    "#f1 = plt.gcf()\n",
    "fnfig = 'out/{}_eval_fig.png'.format(tstring)\n",
    "f1.savefig(fnfig)\n",
    "print(fnfig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
