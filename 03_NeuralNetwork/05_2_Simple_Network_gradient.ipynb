{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a-c)   #개선\n",
    "    sum_exp_a = sum(np.exp(a-c))\n",
    "    y = exp_a/sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 ONE-HOT 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        np.random.seed(0) #항상 동일한 랜덤값 출력을 위함 (수업 목적)\n",
    "        self.W = np.random.randn(2,3) # 정규분포로 초기화\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = simpleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.6, 0.9]) # 입력\n",
    "t = np.array([0.0, 0.0, 1.0]) #정답, TARGET, 정답의 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798],\n",
       "       [ 2.2408932 ,  1.86755799, -0.97727788]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W #어떤값으로 초기화 되어있는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력값을 이용하여 FORWARD 방향 연산해보기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.07523529  1.92089652 -0.2923073 ]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동일한 입력값과 정답을 이용하여 loss 구해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6674507891066104"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient 구해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient_single_point(f, x, verbose=False): \n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    if verbose:\n",
    "        print('x.size={}'.format(x.size)) # (x0, x1) 을 입력으로 받음 --> 2\n",
    "       \n",
    "    for idx in range(x.size): #축별로 계산\n",
    "        v_keep = x[idx]\n",
    "        \n",
    "        # f(x+h) 계산\n",
    "        x[idx] = float(v_keep) + h #n차원 입력 중 해당 차원으로만 h를 더하고\n",
    "        fxh1 = f(x)\n",
    "        if verbose:\n",
    "            print(x, '-->', fxh1)\n",
    "        \n",
    "        # f(x-h) 계산\n",
    "        x[idx] = float(v_keep) - h #n차원 입력 중 해당 차원으로만 h를 빼서\n",
    "        fxh2 = f(x)\n",
    "        if verbose:\n",
    "            print(x, '-->', fxh2)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h) #n차원 방향의 차분을 구함 !\n",
    "        x[idx] = v_keep # 값 복원\n",
    "        \n",
    "        if verbose:\n",
    "            print('grad[{}]={}'.format(idx, grad[idx]))\n",
    "            print()\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, X):\n",
    "    if X.ndim == 1:\n",
    "        return numerical_gradient_single_point(f, X)\n",
    "    else:\n",
    "        grad = np.zeros_like(X)\n",
    "        \n",
    "        for idx, x in enumerate(X):\n",
    "            grad[idx] = numerical_gradient_single_point(f, x)\n",
    "        \n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798],\n",
       "       [ 2.2408932 ,  1.86755799, -0.97727788]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고) lambda\n",
    "\n",
    "    lambda 인자리스트 : 표현식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w): #Loss 산의 높이\n",
    "    return net.loss(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위처럼 해도 되지만, 아래처럼 lambda를 써서 간단히 하는 것도 좋은 방법. 단, 인자로 들어가는 w는 dymmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda w: net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW = numerical_gradient(f, net.W) # 6 방향의 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.44452826  0.14014461 -0.58467287]\n",
      " [ 0.66679239  0.21021692 -0.87700931]]\n"
     ]
    }
   ],
   "source": [
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798],\n",
       "       [ 2.2408932 ,  1.86755799, -0.97727788]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생각해보기\n",
    "\n",
    "* 각 숫자들의 의미를 생각해보기 \n",
    "    :  w11을 h만큼 늘리면 손실함수 값은 대략 0.44만큼 증가한다는 의미이다. 즉 손실함수를 줄일 수 있도록 하는 값을 찾아나가는 것을 의미한다.\n",
    "    \n",
    "    \n",
    "* 교재 135쪽 참고 \n",
    "\n",
    "아래와 같은 방식으로 W를 갱신할 수 있음\n",
    "\n",
    "    net.W = net.W - 0.01 * dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet2:\n",
    "    def __init__(self):\n",
    "        np.random.seed(0) #항상 동일한 랜덤값 출력을 위함 (수업 목적)\n",
    "        self.W = np.random.randn(2,3) # 정규분포로 초기화\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        f = lambda w: net.loss(x, t)\n",
    "        dW = numerical_gradient(f, net.W) # 6 방향의 기울기\n",
    "        \n",
    "        return dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = simpleNet2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798],\n",
       "       [ 2.2408932 ,  1.86755799, -0.97727788]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6, 0.9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.07523529,  1.92089652, -0.2923073 ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44452826,  0.14014461, -0.58467287],\n",
       "       [ 0.66679239,  0.21021692, -0.87700931]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.gradient(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습이 되기 전 랜덤값으로 초기화된 weight로 결과 맞추는지 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.07523529,  1.92089652, -0.2923073 ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74088333, 0.23357527, 0.0255414 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(net2.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(softmax(net2.predict(x))) #추론한 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(t) #정답 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(softmax(net2.predict(x))) == np.argmax(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "steps = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798],\n",
       "       [ 2.2408932 ,  1.86755799, -0.97727788]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6674507891066104"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "vloss = np.zeros((steps, 1))\n",
    "for i in range(steps):\n",
    "    grad = net2.gradient(x, t)\n",
    "    net2.W = net2.W - learning_rate * grad\n",
    "    \n",
    "    loss_i = net2.loss(x, t)\n",
    "    vloss[i] = loss_i\n",
    "    #print(i, grad)\n",
    "print('Done !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.68123023, -1.00128894,  6.82546671],\n",
       "       [-4.42703066, -0.23461124,  7.7928152 ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.60679616344305e-06"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'lr = 0.1')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAi0klEQVR4nO3deZgddZ3v8fen96ydrZNOOqskBEggLCHA4ALIEhAJcxVRZ0YZcRgXrusdR2e8jOLMPDre6zY4+KBwFWUQBZWICIYIAopAJyaBJJCFLRtJZ+skZOl09/f+cSrQNt1JJ+nq6j71eT3PeU6dql/X+VYqT3+6qn71K0UEZmaWXyVZF2BmZtlyEJiZ5ZyDwMws5xwEZmY55yAwM8s5B4GZWc45CCyXJL0g6fys6zDrDRwEZimSVCnpFkk7JL0s6VMHaTtd0v2SNkvyDT7WYxwEZu1IKuvG1X0BmAJMAM4FPiNpdidt9wM/Aa7uxu83OyQHgeWepC9IulPSjyTtAK7qxtW/H/hSRGyLiOXAdztbf0Q8GxE3A0u78fvNDslBYFYwB7gTGALc1n6hpM9K2t7Zq6MVShoKjAYWt5m9GJjW7dWbHYXuPAQ268sei4hfJNN72i+MiC8DXz7MdQ5M3hvbzGsEBh12dWYp8hGBWcGaFNa5K3kf3GbeYGBnCt9ldsQcBGYFB+2lI+mfJO3q7NXhCiO2ARuAGW1mz8DXAKyXcRCYdUFE/HtEDOzsdZAfvRX4vKShko4D/g74fkcNVVAFVCSfqyRVdve2mLXnIDBL178Aq4EXgd8BX42I+wAkjU+OKMYnbSdQuD5x4IhhD/BsD9drOSQ/mMbMLN98RGBmlnMOAjOznHMQmJnlnIPAzCzn+tydxSNGjIiJEydmXYaZWZ+yYMGCzRFR09GyPhcEEydOpL6+PusyzMz6FEkvdrbMp4bMzHLOQWBmlnMOAjOznHMQmJnlXGpBkAyY9YSkxZKWSvpiB22uktQgaVHy+mBa9ZiZWcfS7DW0DzgvInZJKgcelfTriPhju3Z3RMS1KdZhZmYHkVoQRGE0uwPjtJcnL49wZ2bWy6R6jUBSqaRFwCZgXkQ83kGzd0hakjw8fFwn67lGUr2k+oaGhiOqZeXGnXzpnmXsa245op83MytWqQZBRLRExMnAWGCWpOntmvwSmBgRJwHzgB90sp6bImJmRMysqenwxrhDWrttDzc/+jx/fG7rEf28mVmx6pFeQxGxHXgQmN1u/paI2Jd8/B5wWlo1nHXMcPqVl/LAso1pfYWZWZ+UZq+hGklDkul+wAXAM+3ajG7z8TJgeVr1VJWX8qYpI5i/fCN+GI+Z2WvSPCIYDTwoaQnwJIVrBPdIul7SZUmbjyVdSxcDHwOuSrEezj9+FOsb97Jsw440v8bMrE9Js9fQEuCUDuZf12b6c8Dn0qqhvXOPG4kE85dvYtqY6p76WjOzXi1XdxbXDKrk5HFDeGC5rxOYmR2QqyCAwumhJWsb2bhjb9almJn1CrkLgrcePxIonB4yM7McBsHUUYMYO7Qf8316yMwMyGEQSOL840fx6KrN7GnyXcZmZrkLAihcJ9jX3MojK49suAozs2KSyyCYNWkYgyrLfJ3AzIycBkFFWQlvmVrD/Gc20tLqu4zNLN9yGQQAF5wwis27mli0ZnvWpZiZZSq3QXDOsSMpK5FvLjOz3MttEFT3L2fWpGEejdTMci+3QQCF00MrN+3ihc2vZF2KmVlmch0E5x8/CsCnh8ws13IdBOOG9ee42kHM8+khM8uxXAcBFE4P1b+4jW2vNGVdiplZJnIfBOcfP4qW1uDBZ31zmZnlU+6D4MS6akYNrvTpITPLrdwHQUlJYRC6361oYO9+D0JnZvmT+yCAwnWC3U0tPLZ6S9almJn1OAcBcNYxwxlYWcZvlr2cdSlmZj0utSCQVCXpCUmLJS2V9MUO2lRKukPSKkmPS5qYVj0HU1lWyluOreGB5Zto9SB0ZpYzaR4R7APOi4gZwMnAbElntmtzNbAtIiYDXwe+kmI9B3XhtFE07NzHorXbsyrBzCwTqQVBFOxKPpYnr/Z/bs8BfpBM3wm8VZLSqulgzplaGITOvYfMLG9SvUYgqVTSImATMC8iHm/XpA5YAxARzUAjMLyD9VwjqV5SfUNDOk8Vq+5XzhlvGOYgMLPcSTUIIqIlIk4GxgKzJE0/wvXcFBEzI2JmTU1Nt9bY1gXHj2LVpl0870HozCxHeqTXUERsBx4EZrdbtA4YByCpDKgGMuvDecG0WgB+s9S9h8wsP9LsNVQjaUgy3Q+4AHimXbO5wPuT6XcCv42IzLrt1A3px/S6wfzGp4fMLEfSPCIYDTwoaQnwJIVrBPdIul7SZUmbm4HhklYBnwI+m2I9XXLhCbUsfGkbm3buzboUM7MeUZbWiiNiCXBKB/OvazO9F7girRqOxIXTRvG1eSuYv3wT75k1PutyzMxS5zuL25k6ahDjh/X3dQIzyw0HQTuSuGjaKH6/ags79+7Puhwzs9Q5CDpw4bRamlpa+d2KdO5ZMDPrTRwEHTh1/FCGD6jgN0vde8jMip+DoAOlyTMKHnxmE03NrVmXY2aWKgdBJy6cNoqd+5p57Dk/o8DMipuDoBNnTx7BgIpS7nfvITMrcg6CTlSVl3LO1JH8ZulGWvyMAjMrYg6Cg7hoei2bd+3jTy9ty7oUM7PUOAgO4typNVSUlvj0kJkVNQfBQQyqKufsycO5b+nLZDgWnplZqhwEh3DRtFrWbN3D8g07sy7FzCwVDoJDOP+EUZQI7vPpITMrUg6CQxgxsJKZE4dx/9MOAjMrTg6CLrhoWi3PbtzpR1iaWVFyEHTBRdNGAbj3kJkVJQdBF4wd2p8T66r5tU8PmVkRchB00ezptSxes5312/dkXYqZWbdyEHTRxdNrAbjPRwVmVmRSCwJJ4yQ9KGmZpKWSPt5Bm3MkNUpalLyu62hdvcEbagYyddQgB4GZFZ3UHl4PNAOfjoiFkgYBCyTNi4hl7do9EhGXplhHt5k9vZZv/XYlm3buZeSgqqzLMTPrFqkdEUTEhohYmEzvBJYDdWl9X0+4+MRaIvCTy8ysqPTINQJJE4FTgMc7WHyWpMWSfi1pWic/f42kekn1DQ3ZPUd46qhBTBoxwN1IzayopB4EkgYCdwGfiIgd7RYvBCZExAzgP4FfdLSOiLgpImZGxMyamppU6z0YScyeXstjq7ewfXdTZnWYmXWnVINAUjmFELgtIn7WfnlE7IiIXcn0vUC5pBFp1nS0Lp5eS3NrMG+ZTw+ZWXFIs9eQgJuB5RHxtU7a1CbtkDQrqadXPyT4xLpq6ob0881lZlY00uw1dDbwN8BTkhYl8/4JGA8QEd8B3gl8WFIzsAd4d/Tygf8lccmJtXz/Dy+wY+9+BleVZ12SmdlRSS0IIuJRQIdocwNwQ1o1pOXiE0fz3Uee54FlG/kfp47Nuhwzs6PiO4uPwCnjhjCmuop7n9qQdSlmZkfNQXAECr2HRvPwis3s3Ls/63LMzI6Kg+AIve2kWppaWpm/fFPWpZiZHRUHwRE6ZdxQagf79JCZ9X0OgiNUUlK4ueyhFQ3s2tecdTlmZkfMQXAU3nbSaJqaW/ntMz49ZGZ9l4PgKJw2figjB1XyqyXrsy7FzOyIOQiOQkmJuOTE0Tz0rE8PmVnf5SA4SpeeNJp9za3MX+6xh8ysb3IQHKVTxxd6D/1ysXsPmVnf5CA4SiUl4m0njebhFQ007vHNZWbW9zgIusGlJ42mqaWVBzw0tZn1QQ6CbnDyuCHUDenHPe49ZGZ9kIOgG0ji0pNG88jKzX5ymZn1OQ6CbnLpSWNobg0/2N7M+hwHQTeZXjeYCcP780ufHjKzPsZB0E0OnB76w+otbN61L+tyzMy6zEHQjS6bUUdLa3hEUjPrUxwE3Whq7SCOHTWQuYt8esjM+o7UgkDSOEkPSlomaamkj3fQRpK+JWmVpCWSTk2rnp5y2Ywx1L+4jXXb92RdiplZl6R5RNAMfDoiTgDOBD4q6YR2bS4GpiSva4AbU6ynR7x9xhgAfrnYRwVm1jekFgQRsSEiFibTO4HlQF27ZnOAW6Pgj8AQSaPTqqknTBg+gBnjhvj0kJn1GT1yjUDSROAU4PF2i+qANW0+r+X1YdHnXDZjDMs27GDVpl1Zl2JmdkipB4GkgcBdwCciYscRruMaSfWS6hsaGrq3wBRcetJoJJjr00Nm1gekGgSSyimEwG0R8bMOmqwDxrX5PDaZ92ci4qaImBkRM2tqatIpthuNGlzFGZOG8cvF64mIrMsxMzuoNHsNCbgZWB4RX+uk2VzgfUnvoTOBxogoik74l59cx/ObX2HJ2sasSzEzO6g0jwjOBv4GOE/SouR1iaQPSfpQ0uZe4DlgFfBd4CMp1tOjLj5xNBWlJfz8T687wDEz61XK0lpxRDwK6BBtAvhoWjVkqbpfOecdN5J7lqzn8287nrJS37tnZr2Tfzul6PJT6ti8q4lHV23OuhQzs045CFJ07nE1DK4q427fU2BmvZiDIEWVZaW87aTR3L/0ZXY3NWddjplZh7oUBJI+Lmlw0rvnZkkLJV2YdnHF4PKT69jd1MI8P8/YzHqprh4RfCC5GexCYCiF3kBfTq2qInL6xGGMqa5y7yEz67W6GgQHev9cAvwwIpZyiB5BVlBSIuacUscjKzfTsNMPrDGz3qerQbBA0m8oBMH9kgYBremVVVzecWrhgTV3L/JRgZn1Pl0NgquBzwKnR8RuoBz429SqKjKTRw5ixthq7lroIDCz3qerQXAW8GxEbJf018DnAY+dcBjecdpYlm/YwbL1RzTunplZaroaBDcCuyXNAD4NrAZuTa2qIvT2k8ZQXiruWrg261LMzP5MV4OgORkOYg5wQ0R8GxiUXlnFZ+iACs47biR3L1rH/hZfXjGz3qOrQbBT0ucodBv9laQSCtcJ7DC849SxbN7VxCMre/8zFcwsP7oaBFcC+yjcT/AyhecGfDW1qorUOVNHMmxABXct8EVjM+s9uhQEyS//24BqSZcCeyPC1wgOU0VZCZfNGMO8ZRvZvrsp63LMzICuDzHxLuAJ4ArgXcDjkt6ZZmHF6oqZY2lqafVAdGbWa3T11NA/U7iH4P0R8T5gFvC/0yureE0bU830usH8pH5N1qWYmQFdD4KSiNjU5vOWw/hZa+ddM8exdP0Onl7nWzHMLHtd/WV+n6T7JV0l6SrgVxQeM2lHYM6MOirKSvipjwrMrBfo6sXifwBuAk5KXjdFxD+mWVgxq+5fzuxptfxi0Xr27m/Juhwzy7kun96JiLsi4lPJ6+dpFpUH75o5jsY9+/2cAjPL3EGDQNJOSTs6eO2UdNBBcyTdImmTpKc7WX6OpEZJi5LXdUezIX3NXxwznLoh/XzR2Mwyd9AgiIhBETG4g9egiBh8iHV/H5h9iDaPRMTJyev6wym8ryspEVfMHMujqzazZuvurMsxsxxLredPRDwMbE1r/cXgXTPHIeCOJ31UYGbZyboL6FmSFkv6taRpnTWSdI2kekn1DQ3FM07PmCH9OHfqSO6oX+OB6MwsM1kGwUJgQkTMAP4T+EVnDSPipoiYGREza2pqeqq+HvHeM8bTsHMf85f7orGZZSOzIIiIHRGxK5m+FyiXNCKrerJyztSRjK6u4rbHX8q6FDPLqcyCQFKtJCXTs5JatmRVT1ZKS8SVp4/jkZWbeWmLLxqbWc9LLQgk3Q48BkyVtFbS1ZI+JOlDSZN3Ak9LWgx8C3h38vCb3Lny9HGUCG5/0kcFZtbzytJacUS85xDLbwBuSOv7+5LR1f0477hR/LR+DZ88/1gqyrK+hm9meeLfOL3EX50xns27mrh/6ctZl2JmOeMg6CXecmwN44f159bHXsi6FDPLGQdBL1FSIt531gSefGEbS9d7eGoz6zkOgl7kitPGUVVewg8fezHrUswsRxwEvUh1/3IuP7mOXyxaR+Pu/VmXY2Y54SDoZf7mrAns3d/KTxd4/CEz6xkOgl5m2phqTp84lFsfe5HW1lzeVmFmPcxB0Au976yJvLR1N799ZtOhG5uZHSUHQS80e3otY6qruPnR57MuxcxywEHQC5WXlnDV2RN57LktPL3OXUnNLF0Ogl7qytPHM6CilFt8VGBmKXMQ9FLV/cq5YuY45i5ez8uNe7Mux8yKmIOgF/vA2ZNoifCwE2aWKgdBLzZ+eH8uOqGW2x5/id1NzVmXY2ZFykHQy/3dmyfRuGc/P/ED7s0sJQ6CXu60CcM4feJQvvvI837AvZmlwkHQB3zknMms276Huxetz7oUMytCDoI+4JypNRw/ejA3PrTKw06YWbdzEPQBkvjwOcewuuEVfrPMTzAzs+6V5sPrb5G0SdLTnSyXpG9JWiVpiaRT06qlGFwyvZYJw/vzXw+tJsJHBWbWfdI8Ivg+MPsgyy8GpiSva4AbU6ylzysrLeHv33wMS9Y28uiqzVmXY2ZFJLUgiIiHga0HaTIHuDUK/ggMkTQ6rXqKwTtOq2N0dRXfeGCljwrMrNtkeY2gDmjbOX5tMu91JF0jqV5SfUNDQ48U1xtVlpXykXMns+DFbTyy0kcFZtY9+sTF4oi4KSJmRsTMmpqarMvJ1LtmjqVuSD++Nm+FjwrMrFtkGQTrgHFtPo9N5tlBVJaV8tFzJ7NozXYeWpHfoyMz6z5ZBsFc4H1J76EzgcaI2JBhPX3GO08by9ih/fi6jwrMrBuk2X30duAxYKqktZKulvQhSR9KmtwLPAesAr4LfCStWopNRVkJHztvCkvWNvLAcj/O0syOTllaK46I9xxieQAfTev7i91fnlrHjb9bzX/c9wznTq2hrLRPXO4xs17Ivz36qPLSEj5z0VRWbtrFXQvXZl2OmfVhDoI+bPb0Wk4ZP4SvzVvBnqaWrMsxsz7KQdCHSeJzFx/Pxh37uOX3fraxmR0ZB0EfN2vSMM4/fhTfeWg1W19pyrocM+uDHARF4LMXT+WVpma+8cCKrEsxsz7IQVAEJo8cxF+fOYEf/fFFlq3fkXU5ZtbHOAiKxKcuOJbqfuV8Ye5S32RmZofFQVAkhvSv4B8uOo4nXtjK3MV+pKWZdZ2DoIhcefo4ptcN5t/vXc4r+5qzLsfM+ggHQREpLRFfvGw6G3fs41vzV2Zdjpn1EQ6CInPahKFcOXMc33v0eZ5e15h1OWbWBzgIitA/XXI8wwZU8I93LaG5pTXrcsysl3MQFKHq/uV8ac40lq7fwXcf8R3HZnZwDoIiNXv6aGZPq+XrD6zguYZdWZdjZr2Yg6CIXT9nGlVlJfzDnT5FZGadcxAUsZGDq/jS5dNZ8OI2/uuh1VmXY2a9lIOgyM05uY45J4/hm/NX8qeXtmVdjpn1Qg6CHLh+znRqB1fxiTsWscs3mplZOw6CHKjuV87XrzyZNVt3c93dT3ssIjP7M6kGgaTZkp6VtErSZztYfpWkBkmLktcH06wnz2ZNGsa1503hZwvX8d9PvJR1OWbWi6T28HpJpcC3gQuAtcCTkuZGxLJ2Te+IiGvTqsNe8/G3TmHxmu18Ye5SThg9mFPGD826JDPrBdI8IpgFrIqI5yKiCfgxMCfF77NDKC0R33z3yYwaXMVHblvI5l37si7JzHqBNIOgDljT5vPaZF5775C0RNKdksalWI9RGK76O399GltfaeKjty2kqdn3F5jlXdYXi38JTIyIk4B5wA86aiTpGkn1kuobGhp6tMBiNL2umq+84yQef34r/3jXEl88Nsu5NINgHdD2L/yxybxXRcSWiDhwfuJ7wGkdrSgiboqImRExs6amJpVi8+byU+r49AXH8vM/reNr8/ysY7M8S+1iMfAkMEXSJAoB8G7gvW0bSBodERuSj5cBy1Osx9q59rzJrN22h//87SrGDu3HlaePz7okM8tAakEQEc2SrgXuB0qBWyJiqaTrgfqImAt8TNJlQDOwFbgqrXrs9STxr385nQ079vK5nz1F/4oy3j5jTNZlmVkPU187Pzxz5syor6/PuoyisrupmatueZIFL23j2+89hdnTR2ddkpl1M0kLImJmR8uyvlhsvUD/ijJu+dvTmTG2mmv/+0/MW7Yx65LMrAc5CAyAgZVlfP8Ds5hWV82Hf7SAuxetO/QPmVlRcBDYqwZXlfPDq2dx2oShfPzHi7jlUT/dzCwPHAT2ZwZXlfODD8xi9rRarr9nGV/+9TO0tvat60hmdngcBPY6VeWlfPuvTuW9Z4znO79bzTU/XMDOvfuzLsvMUuIgsA6Vloh/u3w6X3j7CTz47CYu//bvWe1nH5sVJQeBdUoSV509iR9dfQbbdu9nzg2/5+d/WushKcyKjIPADumsY4bzy//5Ro4fPYhP3rGYj/14EY17fKrIrFg4CKxL6ob048fXnMX/uvBYfv3UBi7+xsPMX+77DcyKgYPAuqy0RFx73hTu+vBfMKCyjKt/UM/f/7CeDY17si7NzI6Cg8AO24xxQ/jVx97EZ2ZP5XcrGnjr//0d33xgJa/sa866NDM7Ag4COyIVZSV85JzJzPvkW3jzlBq+/sAK3vLVB7n1sRfY19ySdXlmdhg86Jx1i4UvbePLv36GJ57fyqjBlXzwjW/gPWeMZ2BlmiOdm1lXHWzQOQeBdZuI4NFVm7nxodX8YfUWBleVceXp43jvGROYNGJA1uWZ5ZqDwHrcojXb+e7Dz3H/0pdpbg3eOHkEV8wcy/nHj2KAjxLMepyDwDKzacdeflK/htufWMO67XvoV17KBSeM4pITa3nTlBqHglkPcRBY5lpbg/oXt3H3onXc+9QGtu3eT0VpCWceM5xzp9Zw9uQRTBk5EElZl2pWlBwE1qs0t7RS/+I2Hli2kQeWb+SFLbsBqBlUyRmThnHahKGcOn4oJ4wZTHmpO7aZdQcHgfVqa7bu5g+rN/P7VVuof2Er6xv3AlBRWsLU2kFMrxvM8aMHM2XkII4dNZDhAyszrtis73EQWJ+yoXEPC17cxlNrG3l6fSNL1+9g++7XxjYa2r+ciSMGMHH4ACYM78/Yof0ZO7QfdUP6MXJwJZVlpRlWb9Y7ZRYEkmYD3wRKge9FxJfbLa8EbgVOA7YAV0bECwdbp4MgfyKCjTv2sWLjTlZu2sXqhl28sPkVXtj8yqtHD20NG1DBqMFVjBhYQc3ASkYMqmTYgAqG9a9gSP9yhvSvoLpfOdX9yhlUVUb/ilJfm7Cid7AgSK3LhqRS4NvABcBa4ElJcyNiWZtmVwPbImKypHcDXwGuTKsm65skUVtdRW11FW8+tubPlu1rbmHD9r2s3baH9dv38PKOvby8Yy+bduylYVcTzzW8QsOufTQ1t3a6/tISMbCyjIGVhVAYkLz3ryilX0UZ/cpLqCovLbzKSqgsL6WyrISKshIqSpP3shLKSwufy0pFWUkJ5aWitESUvzpPlJaUUCpRWipKJUpKKHwuESUlenVaghIpeeGgslSl2XdvFrAqIp4DkPRjYA7QNgjmAF9Ipu8EbpCk6GvnqywzlWWlhdNEB7lhLSLYs7+Fra80se2V/TTuKby272li195mdu5tZufe/eza18LupmZ27WtmT1ML23fvZ8/+Fvbub3n1fe/+zgMlTQeCQSTv+vN5OjCvg2k4MF2Yem1Zsu5k3mvtXh86B77vQPu281+d7rR2HbJN5wuOqFmH390bHW51V54+jg++6Q3dXkeaQVAHrGnzeS1wRmdtIqJZUiMwHNjctpGka4BrAMaPH59WvVakJNG/ooz+FWWMHXp064oI9rcEe5tbaGpufe3V0sr+llb2t0Ty3kpzS9DcWnhvaQ32twatrUFza9DS2kpLK7REYV5La9AaB96hNZkfvH66pRWCIIJX50fyMwdqPDAPXmv72rx4bVkUlr82/dr8V7eZ1xa0/Qut7d9rnf3l9ufr6fzftCsO+6/DXv7nZBxBgSNS6ijRJ+7miYibgJugcI0g43IsxyRRUSYqytyt1YpHmv+b1wHj2nwem8zrsI2kMqCawkVjMzPrIWkGwZPAFEmTJFUA7wbmtmszF3h/Mv1O4Le+PmBm1rNSOzWUnPO/FrifQvfRWyJiqaTrgfqImAvcDPxQ0ipgK4WwMDOzHpTqNYKIuBe4t92869pM7wWuSLMGMzM7OF/xMjPLOQeBmVnOOQjMzHLOQWBmlnN9bvRRSQ3Ai0f44yNod9dyTuRxu/O4zZDP7c7jNsPhb/eEiKjpaEGfC4KjIam+s9H3ilketzuP2wz53O48bjN073b71JCZWc45CMzMci5vQXBT1gVkJI/bncdthnxudx63Gbpxu3N1jcDMzF4vb0cEZmbWjoPAzCznchMEkmZLelbSKkmfzbqeNEgaJ+lBScskLZX08WT+MEnzJK1M3o/yOV29k6RSSX+SdE/yeZKkx5N9fkcyHHrRkDRE0p2SnpG0XNJZedjXkj6Z/P9+WtLtkqqKcV9LukXSJklPt5nX4f5VwbeS7V8i6dTD+a5cBIGkUuDbwMXACcB7JJ2QbVWpaAY+HREnAGcCH02287PA/IiYAsxPPhejjwPL23z+CvD1iJgMbAOuzqSq9HwTuC8ijgNmUNj2ot7XkuqAjwEzI2I6hSHu301x7uvvA7Pbzets/14MTEle1wA3Hs4X5SIIgFnAqoh4LiKagB8DczKuqdtFxIaIWJhM76Twi6GOwrb+IGn2A+DyTApMkaSxwNuA7yWfBZwH3Jk0KartllQNvJnCMz2IiKaI2E4O9jWF4fP7JU817A9soAj3dUQ8TOE5LW11tn/nALdGwR+BIZJGd/W78hIEdcCaNp/XJvOKlqSJwCnA48CoiNiQLHoZGJVVXSn6BvAZoDX5PBzYHhHNyedi2+eTgAbg/yWnw74naQBFvq8jYh3wf4CXKARAI7CA4t7XbXW2f4/qd1xegiBXJA0E7gI+ERE72i5LHgVaVH2GJV0KbIqIBVnX0oPKgFOBGyPiFOAV2p0GKtJ9PZTCX7+TgDHAAF5/+iQXunP/5iUI1gHj2nwem8wrOpLKKYTAbRHxs2T2xgOHicn7pqzqS8nZwGWSXqBw2u88CufPhySnD6D49vlaYG1EPJ58vpNCMBT7vj4feD4iGiJiP/AzCvu/mPd1W53t36P6HZeXIHgSmJL0LKigcHFpbsY1dbvkvPjNwPKI+FqbRXOB9yfT7wfu7una0hQRn4uIsRExkcK+/W1E/BXwIPDOpFlRbXdEvAyskTQ1mfVWYBlFvq8pnBI6U1L/5P/7ge0u2n3dTmf7dy7wvqT30JlAY5tTSIcWEbl4AZcAK4DVwD9nXU9K2/hGCoeKS4BFyesSCufL5wMrgQeAYVnXmuK/wTnAPcn0G4AngFXAT4HKrOvr5m09GahP9vcvgKF52NfAF4FngKeBHwKVxbivgdspXAfZT+EI8OrO9i8gCj0jVwNPUehV1eXv8hATZmY5l5dTQ2Zm1gkHgZlZzjkIzMxyzkFgZpZzDgIzs5xzEJgdBkmfkNQ/6zrMupO7j5odhuTu5ZkRsTnrWsy6i48IzDohaYCkX0lanIx9/y8Uxrd5UNKDSZsLJT0maaGknybjPCHpBUn/IekpSU9ImpzMvyJZ12JJD2e3dWavcRCYdW42sD4iZkRh7PtvAOuBcyPiXEkjgM8D50fEqRTu8v1Um59vjIgTgRuSnwW4DrgoImYAl/XMZpgdnIPArHNPARdI+oqkN0VEY7vlZ1J40NHvJS2iMPbLhDbLb2/zflYy/Xvg+5L+jsJDVcwyV3boJmb5FBErkkf+XQL8q6T57ZoImBcR7+lsFe2nI+JDks6g8BCdBZJOi4gt3V272eHwEYFZJySNAXZHxI+Ar1IY5nknMChp8kfg7Dbn/wdIOrbNKq5s8/5Y0uaYiHg8Iq6j8GCZtkMHm2XCRwRmnTsR+KqkVgojQH6Ywime+yStT64TXAXcLqky+ZnPUxjlFmCopCXAPuDAUcNXJU2hcDQxH1jcM5ti1jl3HzVLgbuZWl/iU0NmZjnnIwIzs5zzEYGZWc45CMzMcs5BYGaWcw4CM7OccxCYmeXc/wfyjnnNEuFVkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(vloss)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('loss')\n",
    "plt.title('lr = {}'.format(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction /Infererence (추론과정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.59306573, -0.81192348, 11.10881371])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.57780093e-08, 6.65099633e-06, 9.99993293e-01])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(net2.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(softmax(net2.predict(x))) # 추론한 클래스 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(softmax(net2.predict(x))) == np.argmax(t) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
